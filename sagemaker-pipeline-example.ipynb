{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8872cb-9420-4922-8d54-a5ab6c38080c",
   "metadata": {},
   "source": [
    "# Create a SageMaker pipeline to run a Processing job for model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2cdb92-7803-4746-9ec6-494df14538fc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Generally, when working with SageMaker processing jobs, the input data is expected to be stored in Amazon S3 and the SageMaker platform will handle data downloading from S3 and save the output results back to S3. In this way, users can achieve better lineage between the input data and output results, which also benefits the reproducability and auditability of the job. However, sometimes users would like to directly read data from their data storage without saving the data to S3 as an additional step for the processing job. In fact, it is possible to bypass the S3 data input for the processing jobs and directly read the data from other data storage given the proper connector is available. \n",
    "\n",
    "Processing job is suitable for many use cases beyond just data pre-processing. It basically launches a cluster of instances, run the specified docker container and execute the python script provided for the job in the running container image. Users can design their script to do model training, model inference and so on. To automate the job with event driven action, you can create the processing job as a step in a SageMaker pipeline and trigger the pipeline using EventBridge based on a schedule or an event-based event.\n",
    "\n",
    "In this notebook, we will demonstrate how to create a SageMaker processing job in a pipeline and trigger this pipleine using EventBridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec08aaf-055e-4e82-a24b-95275e537029",
   "metadata": {},
   "source": [
    "### Section 1: Traditional way to run job and inference as python code\n",
    "Firstly, let's write a script that performs model training and inference. This is typically how data scientist build and test their code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcf52b-d77f-4d65-b57a-242de55237f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Support Vector Regression: \n",
    "\n",
    "#1 Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import savetxt\n",
    "output_file = \"predict_output.csv\"\n",
    "\n",
    "#2 Importing the dataset\n",
    "dataset = pd.read_csv('data/Position_Salaries.csv')\n",
    "X = dataset.iloc[:,1:2].values.astype(float)\n",
    "y = dataset.iloc[:,2:3].values.astype(float)\n",
    "\n",
    "#3 Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "y = sc_y.fit_transform(y)\n",
    "\n",
    "#4 Fitting the Support Vector Regression Model to the dataset\n",
    "# Create your support vector regressor here\n",
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\n",
    "#SVR. We have a non-linear condition so we can select polynomial or gaussian but here\n",
    "#we select RBF(a gaussian type) kernel. \n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(X,y)\n",
    "\n",
    "#5 Predicting a new result\n",
    "y_pred = sc_y.inverse_transform((regressor.predict(sc_X.transform(np.array([[6.5]])))))\n",
    "\n",
    "y_out = regressor.predict(X_grid)\n",
    "savetxt(output_file, y_out, delimiter=',')\n",
    "\n",
    "#6 Visualising the Support Vector Regression results\n",
    "plt.scatter(X, y, color = 'magenta')\n",
    "plt.plot(X, regressor.predict(X), color = 'green')\n",
    "plt.title('Truth or Bluff (Support Vector Regression Model)')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n",
    "\n",
    "#6 Visualising the Regression results (for higher resolution and smoother curve)\n",
    "X_grid = np.arange(min(X), max(X), 0.1)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n",
    "plt.title('Truth or Bluff (Support Vector Regression Model(High Resolution))')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b98c8-01ed-4276-b33c-f918293183d9",
   "metadata": {},
   "source": [
    "you can check the output in the `predict_output.csv` from the left-hand side folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7dde6-07af-44f8-a40e-5d7f807da488",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Section 2: Run the script in a Processing job\n",
    "Next step, we show how to convert the script into a SageMaker processing job using SageMaker python SDK, which is a high level api. Firstly, import the necessary packaged and define the role and bucket info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d13b1b7e-db2b-40ca-9b0f-8eb3ebe9b922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'processing-job-sagemaker'\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b28df16-2bca-48bb-9ce7-d695d4feba89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_location = sess.upload_data(\n",
    "    './data/Position_Salaries.csv', key_prefix=\"{}/data\".format(prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd67c099-3c70-4226-8ffe-30a68aac49b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/Support_Vector_Regression.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/Support_Vector_Regression.py\n",
    "\n",
    "#1 Importing the libraries\n",
    "import json\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import savetxt\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "output_file = \"predict_output.csv\"\n",
    "\n",
    "def parse_args() -> None:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--base_dir', type=str, default=\"/opt/ml/processing\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting job\")\n",
    "    args = parse_args()\n",
    "    base_dir = args.base_dir\n",
    "    input_dir = os.path.join(base_dir, \"data\")\n",
    "    \n",
    "    input_file_list = glob.glob(f\"{input_dir}/*.csv\")\n",
    "    #2 Concat input files with select columns\n",
    "    df = []\n",
    "    for file in input_file_list:\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df.append(df_tmp)\n",
    "    dataset = pd.concat(df, ignore_index=True)\n",
    "        \n",
    "    print(\"Data loaded in to a dataframe\")\n",
    "\n",
    "        \n",
    "    X = dataset.iloc[:,1:2].values.astype(float)\n",
    "    y = dataset.iloc[:,2:3].values.astype(float)\n",
    "\n",
    "    #3 Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(X)\n",
    "    y = sc_y.fit_transform(y)\n",
    "\n",
    "    #4 Fitting the Support Vector Regression Model to the dataset\n",
    "    # Create your support vector regressor here\n",
    "    from sklearn.svm import SVR\n",
    "    # most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\n",
    "    #SVR. We have a non-linear condition so we can select polynomial or gaussian but here\n",
    "    #we select RBF(a gaussian type) kernel. \n",
    "    regressor = SVR(kernel='rbf')\n",
    "    regressor.fit(X,y)\n",
    "\n",
    "    #5 Predicting a new result\n",
    "    y_pred = sc_y.inverse_transform((regressor.predict(sc_X.transform(np.array([[6.5]])))))\n",
    "    \n",
    "    X_grid = np.arange(min(X), max(X), 0.1)\n",
    "    X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "\n",
    "    y_out = regressor.predict(X_grid)\n",
    "    savetxt(f\"{base_dir}/output/{output_file}\", y_out, delimiter=',')\n",
    "    print(\"finish processing job\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f03785b-9b87-4ffe-a0b5-f37367be2e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_job_name = 'sagemaker-processing-job'\n",
    "est_cls = SKLearn\n",
    "#Initialize the FrameworkProcessor\n",
    "sklearn = FrameworkProcessor(\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version='0.23-1',\n",
    "    role=get_execution_role(),\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1, \n",
    "    base_job_name=base_job_name,\n",
    ")\n",
    "\n",
    "processing_job_name = name_from_base(base_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be9f361c-221f-4297-9a9d-a19146f607f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-631450739534/sagemaker-processing-job-2023-03-07-11-57-21-451/source/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-631450739534/sagemaker-processing-job-2023-03-07-11-57-21-451/source/runproc.sh\n",
      "INFO:sagemaker:Creating processing-job with name sagemaker-processing-job-2023-03-07-11-57-21-451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\u001b[34mFound existing installation: typing 3.7.4.3\u001b[0m\n",
      "\u001b[34mUninstalling typing-3.7.4.3:\n",
      "  Successfully uninstalled typing-3.7.4.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 86.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting sagemaker\n",
      "  Downloading sagemaker-2.135.1.post0.tar.gz (674 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 674.4/674.4 kB 59.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting packaging>=20.0\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.7/42.7 kB 7.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 1)) (9.3.0)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 71.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /miniconda3/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.19.2)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 20.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 965.4/965.4 kB 72.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting attrs<23,>=20.3.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 kB 8.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting boto3<2.0,>=1.26.28\n",
      "  Downloading boto3-1.26.85-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 22.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 13.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0,>=3.1 in /miniconda3/lib/python3.7/site-packages (from sagemaker->-r requirements.txt (line 2)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting protobuf3-to-dict<1.0,>=0.1.5\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata<5.0,>=1.4.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.7/site-packages (from sagemaker->-r requirements.txt (line 2)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting pathos\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 16.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting schema\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 2)) (1.0.1)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.30.0,>=1.29.85\n",
      "  Downloading botocore-1.29.85-py3-none-any.whl (10.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.5/10.5 MB 96.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /miniconda3/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 2)) (0.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker->-r requirements.txt (line 2)) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker->-r requirements.txt (line 2)) (3.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.7/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas->sagemaker->-r requirements.txt (line 2)) (2022.6)\u001b[0m\n",
      "\u001b[34mCollecting pox>=0.3.2\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting ppft>=1.7.6.6\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 11.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting dill>=0.3.6\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 21.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multiprocess>=0.70.14\n",
      "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.7/115.7 kB 22.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting contextlib2>=0.5.5\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /miniconda3/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.85->boto3<2.0,>=1.26.28->sagemaker->-r requirements.txt (line 2)) (1.26.12)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.135.1.post0-py2.py3-none-any.whl size=911932 sha256=629ed2657d869f04cec72554ba247496d3ef43f72a18f52133b3d5b6bdf98f5e\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/ae/23/f29272e54ddc56a3d5c1c2d340e1a98ec2d67445d41244973f\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\n",
      "  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4015 sha256=fc424dbd4833bfd25589e66a2aeba51e27d589088dbda7234c84d2d9137c9bb2\n",
      "  Stored in directory: /root/.cache/pip/wheels/f6/30/95/7b1c0079a0aecb008371bdfce5aae454fc15974af2f917b742\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[34mInstalling collected packages: smdebug_rulesconfig, pyparsing, protobuf3-to-dict, ppft, pox, packaging, kiwisolver, importlib-metadata, google-pasta, fonttools, dill, cycler, contextlib2, attrs, schema, multiprocess, matplotlib, botocore, pathos, boto3, sagemaker\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.1.0\n",
      "    Uninstalling importlib-metadata-5.1.0:\n",
      "      Successfully uninstalled importlib-metadata-5.1.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.18\n",
      "    Uninstalling botocore-1.27.18:\n",
      "      Successfully uninstalled botocore-1.27.18\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.24.17\n",
      "    Uninstalling boto3-1.24.17:\n",
      "      Successfully uninstalled boto3-1.24.17\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires boto3==1.24.17, but you have boto3 1.26.85 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires botocore==1.27.18, but you have botocore 1.29.85 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-22.2.0 boto3-1.26.85 botocore-1.29.85 contextlib2-21.6.0 cycler-0.11.0 dill-0.3.6 fonttools-4.38.0 google-pasta-0.2.0 importlib-metadata-4.13.0 kiwisolver-1.4.4 matplotlib-3.5.3 multiprocess-0.70.14 packaging-23.0 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 pyparsing-3.0.9 sagemaker-2.135.1.post0 schema-0.7.5 smdebug_rulesconfig-1.0.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.3.1 -> 23.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mStarting job\u001b[0m\n",
      "\u001b[34mData loaded in to a dataframe\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run the processing job\n",
    "sklearn.run(\n",
    "    code='Support_Vector_Regression.py',\n",
    "    source_dir='code',\n",
    "    arguments = [\n",
    "                 '--base_dir', '/opt/ml/processing', # you can also ignore this arguments as it has a default value\n",
    "                ],\n",
    "    inputs = [\n",
    "        ProcessingInput\n",
    "        (\n",
    "            source=data_location,\n",
    "            destination=\"/opt/ml/processing/data\",\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"output\", source=\"/opt/ml/processing/output\"),\n",
    "    ],\n",
    "    job_name=processing_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af404dba-6141-448f-a330-6312d0804b28",
   "metadata": {},
   "source": [
    "### Section 3: Create a SageMaker pipeline with one step of the processing job\n",
    "Now we can create a SageMaker pipeline based on the processing job. You can directly come to this section without executing previous cells in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b271c76f-b838-4e4c-b154-7e7ab4530b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'processing-job-sagemaker'\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "pipeline_session = sagemaker.workflow.pipeline_context.PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ab792bb-7b50-4d82-8efb-0fffe26bcba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-631450739534/processing-job-sagemaker/data/Position_Salaries.csv\n"
     ]
    }
   ],
   "source": [
    "data_location = sess.upload_data(\n",
    "    './data/Position_Salaries.csv', key_prefix=\"{}/data\".format(prefix)\n",
    ")\n",
    "print(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76b7cf03-1631-44c8-9035-a504160d1de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=data_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c341d425-bf65-45f1-8588-a72eeee2d035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# processing step for model training and inference\n",
    "base_job_name = 'sagemaker-processing-job'\n",
    "est_cls = SKLearn\n",
    "\n",
    "sklearn = FrameworkProcessor(\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version='0.23-1',\n",
    "    role=get_execution_role(),\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1, \n",
    "    base_job_name=base_job_name,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "\n",
    "step_args = sklearn.run(\n",
    "    code='Support_Vector_Regression.py',\n",
    "    source_dir='code',\n",
    "    arguments = [\n",
    "                 '--base_dir', '/opt/ml/processing', # you can also ignore this arguments as it has a default value\n",
    "                ],\n",
    "    inputs = [\n",
    "        ProcessingInput\n",
    "        (\n",
    "            source=data_location,\n",
    "            destination=\"/opt/ml/processing/data\",\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"output\", source=\"/opt/ml/processing/output\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "   name=\"TrainandInference\",\n",
    "   step_args=step_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83c195-124e-451c-bbe6-1699e07a52bd",
   "metadata": {},
   "source": [
    "Next we can define the pipeline based on the processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98cfa04f-73d3-42d6-b24f-aa3d1d87df58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"demo-pipeline-processing-job-automate\",\n",
    "    parameters=[\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_process],\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7e548-4a6c-4eac-a5d9-10477e6a176d",
   "metadata": {},
   "source": [
    "#### Submit the pipeline to SageMaker and start execution\n",
    "Submit the pipeline definition to the Pipeline service. The role passed in will be used by the Pipeline service to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67d34906-e001-4a97-8c17-85688ea49ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-631450739534/demo-pipeline-processing-job-automate/code/4f09f48afe6dd85075f5ac92e4a21fc1/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-631450739534/demo-pipeline-processing-job-automate/code/992719e14f8c86020e0dc55f1d15bdb8/runproc.sh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:631450739534:pipeline/demo-pipeline-processing-job-automate',\n",
       " 'ResponseMetadata': {'RequestId': 'f2e008c5-3922-4123-877a-eaa03a9a1db6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f2e008c5-3922-4123-877a-eaa03a9a1db6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '105',\n",
       "   'date': 'Tue, 07 Mar 2023 12:03:41 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77c47c0c-e847-405d-ab75-df8a0c76ecc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:631450739534:pipeline/demo-pipeline-processing-job-automate',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:631450739534:pipeline/demo-pipeline-processing-job-automate/execution/9rerujuyxyho',\n",
       " 'PipelineExecutionDisplayName': 'execution-1678190622509',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2023, 3, 7, 12, 3, 42, 431000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 3, 7, 12, 3, 42, 431000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:631450739534:user-profile/d-lh0rkivhzfhz/sagemaker-user',\n",
       "  'UserProfileName': 'sagemaker-user',\n",
       "  'DomainId': 'd-lh0rkivhzfhz'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:631450739534:user-profile/d-lh0rkivhzfhz/sagemaker-user',\n",
       "  'UserProfileName': 'sagemaker-user',\n",
       "  'DomainId': 'd-lh0rkivhzfhz'},\n",
       " 'ResponseMetadata': {'RequestId': '7a6c0177-3eea-42ab-b5a4-2cb408b5fb3c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7a6c0177-3eea-42ab-b5a4-2cb408b5fb3c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '769',\n",
       "   'date': 'Tue, 07 Mar 2023 12:03:42 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution = pipeline.start()\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da97354f-3596-4002-bc2e-f6b16e82c463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wait for the execution to complete.\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce4473-8ba1-4327-bb27-60e635bb0a47",
   "metadata": {},
   "source": [
    "You can also monitor the pipeline execution from the Studio **Home** page under **Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f79cd-b8d9-4291-9bca-841d0afd5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "After you have setup the EventBridge event to tigg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec909267-f6fe-40fb-a46e-fd0687069060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = boto3.client('s3')\n",
    "# df = pd.read_csv(\"data/Position_Salaries.csv\")\n",
    "# from io import BytesIO\n",
    "# csv_buffer = BytesIO()\n",
    "# df.to_csv(csv_buffer)\n",
    "# content = csv_buffer.getvalue()\n",
    "# k = f\"{prefix}/data/Position_Salaries.csv\"\n",
    "# response = client.put_object(Bucket=bucket, Key=k, Body=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208b729-e298-4c34-ac82-3a55f2b8f564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
