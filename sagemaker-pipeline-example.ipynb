{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8872cb-9420-4922-8d54-a5ab6c38080c",
   "metadata": {},
   "source": [
    "# Create a SageMaker pipeline to run a Processing job for model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2cdb92-7803-4746-9ec6-494df14538fc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Generally, when working with SageMaker processing jobs, the input data is expected to be stored in Amazon S3 and the SageMaker platform will handle data downloading from S3 and save the output results back to S3. In this way, users can achieve better lineage between the input data and output results, which also benefits the reproducability and auditability of the job. However, sometimes users would like to directly read data from their data storage without saving the data to S3 as an additional step for the processing job. In fact, it is possible to bypass the S3 data input for the processing jobs and directly read the data from other data storage given the proper connector is available. \n",
    "\n",
    "Processing job is suitable for many use cases beyond just data pre-processing. It basically launches a cluster of instances, run the specified docker container and execute the python script provided for the job in the running container image. Users can design their script to do model training, model inference and so on. To automate the job with event driven action, you can create the processing job as a step in a SageMaker pipeline and trigger the pipeline using EventBridge based on a schedule or an event-based event.\n",
    "\n",
    "In this notebook, we will demonstrate how to create a SageMaker processing job in a pipeline and trigger this pipleine using EventBridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec08aaf-055e-4e82-a24b-95275e537029",
   "metadata": {},
   "source": [
    "### Section 1: Traditional way to run job and inference as python code\n",
    "Firstly, let's write a script that performs model training and inference. This is typically how data scientist build and test their code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcf52b-d77f-4d65-b57a-242de55237f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Support Vector Regression: \n",
    "\n",
    "#1 Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import savetxt\n",
    "output_file = \"predict_output.csv\"\n",
    "\n",
    "#2 Importing the dataset\n",
    "dataset = pd.read_csv('data/Position_Salaries.csv')\n",
    "X = dataset.iloc[:,1:2].values.astype(float)\n",
    "y = dataset.iloc[:,2:3].values.astype(float)\n",
    "\n",
    "#3 Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "y = sc_y.fit_transform(y)\n",
    "\n",
    "#4 Fitting the Support Vector Regression Model to the dataset\n",
    "# Create your support vector regressor here\n",
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\n",
    "#SVR. We have a non-linear condition so we can select polynomial or gaussian but here\n",
    "#we select RBF(a gaussian type) kernel. \n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(X,y)\n",
    "\n",
    "#5 Predicting a new result\n",
    "y_pred = sc_y.inverse_transform((regressor.predict(sc_X.transform(np.array([[6.5]])))))\n",
    "\n",
    "y_out = regressor.predict(X_grid)\n",
    "savetxt(output_file, y_out, delimiter=',')\n",
    "\n",
    "#6 Visualising the Support Vector Regression results\n",
    "plt.scatter(X, y, color = 'magenta')\n",
    "plt.plot(X, regressor.predict(X), color = 'green')\n",
    "plt.title('Truth or Bluff (Support Vector Regression Model)')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n",
    "\n",
    "#6 Visualising the Regression results (for higher resolution and smoother curve)\n",
    "X_grid = np.arange(min(X), max(X), 0.1)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n",
    "plt.title('Truth or Bluff (Support Vector Regression Model(High Resolution))')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b98c8-01ed-4276-b33c-f918293183d9",
   "metadata": {},
   "source": [
    "you can check the output in the `predict_output.csv` from the left-hand side folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7dde6-07af-44f8-a40e-5d7f807da488",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Section 2: Run the script in a Processing job\n",
    "Next step, we show how to convert the script into a SageMaker processing job using SageMaker python SDK, which is a high level api. Firstly, import the necessary packaged and define the role and bucket info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b1b7e-db2b-40ca-9b0f-8eb3ebe9b922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'processing-job-sagemaker'\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28df16-2bca-48bb-9ce7-d695d4feba89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_location = sess.upload_data(\n",
    "    './data/Position_Salaries.csv', key_prefix=\"{}/data\".format(prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67c099-3c70-4226-8ffe-30a68aac49b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile code/Support_Vector_Regression.py\n",
    "\n",
    "#1 Importing the libraries\n",
    "import json\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import savetxt\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "output_file = \"predict_output.csv\"\n",
    "\n",
    "def parse_args() -> None:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--base_dir', type=str, default=\"/opt/ml/processing\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting job\")\n",
    "    args = parse_args()\n",
    "    base_dir = args.base_dir\n",
    "    input_dir = os.path.join(base_dir, \"data\")\n",
    "    \n",
    "    input_file_list = glob.glob(f\"{input_dir}/*.csv\")\n",
    "    #2 Concat input files with select columns\n",
    "    df = []\n",
    "    for file in input_file_list:\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df.append(df_tmp)\n",
    "    dataset = pd.concat(df, ignore_index=True)\n",
    "        \n",
    "    print(\"Data loaded in to a dataframe\")\n",
    "\n",
    "        \n",
    "    X = dataset.iloc[:,1:2].values.astype(float)\n",
    "    y = dataset.iloc[:,2:3].values.astype(float)\n",
    "\n",
    "    #3 Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(X)\n",
    "    y = sc_y.fit_transform(y)\n",
    "\n",
    "    #4 Fitting the Support Vector Regression Model to the dataset\n",
    "    # Create your support vector regressor here\n",
    "    from sklearn.svm import SVR\n",
    "    # most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\n",
    "    #SVR. We have a non-linear condition so we can select polynomial or gaussian but here\n",
    "    #we select RBF(a gaussian type) kernel. \n",
    "    regressor = SVR(kernel='rbf')\n",
    "    regressor.fit(X,y)\n",
    "\n",
    "    #5 Predicting a new result\n",
    "    y_pred = sc_y.inverse_transform((regressor.predict(sc_X.transform(np.array([[6.5]])))))\n",
    "    \n",
    "    X_grid = np.arange(min(X), max(X), 0.1)\n",
    "    X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "\n",
    "    y_out = regressor.predict(X_grid)\n",
    "    savetxt(f\"{base_dir}/output/{output_file}\", y_out, delimiter=',')\n",
    "    print(\"finish processing job\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03785b-9b87-4ffe-a0b5-f37367be2e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_job_name = 'sagemaker-processing-job'\n",
    "est_cls = SKLearn\n",
    "#Initialize the FrameworkProcessor\n",
    "sklearn = FrameworkProcessor(\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version='0.23-1',\n",
    "    role=get_execution_role(),\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1, \n",
    "    base_job_name=base_job_name,\n",
    ")\n",
    "\n",
    "processing_job_name = name_from_base(base_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f361c-221f-4297-9a9d-a19146f607f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run the processing job\n",
    "sklearn.run(\n",
    "    code='Support_Vector_Regression.py',\n",
    "    source_dir='code',\n",
    "    arguments = [\n",
    "                 '--base_dir', '/opt/ml/processing', # you can also ignore this arguments as it has a default value\n",
    "                ],\n",
    "    inputs = [\n",
    "        ProcessingInput\n",
    "        (\n",
    "            source=data_location,\n",
    "            destination=\"/opt/ml/processing/data\",\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"output\", source=\"/opt/ml/processing/output\"),\n",
    "    ],\n",
    "    job_name=processing_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af404dba-6141-448f-a330-6312d0804b28",
   "metadata": {},
   "source": [
    "### Section 3: Create a SageMaker pipeline with one step of the processing job\n",
    "Now we can create a SageMaker pipeline based on the processing job. You can directly come to this section without executing previous cells in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b271c76f-b838-4e4c-b154-7e7ab4530b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'processing-job-sagemaker'\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "pipeline_session = sagemaker.workflow.pipeline_context.PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab792bb-7b50-4d82-8efb-0fffe26bcba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_location = sess.upload_data(\n",
    "    './data/Position_Salaries.csv', key_prefix=\"{}/data\".format(prefix)\n",
    ")\n",
    "print(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7cf03-1631-44c8-9035-a504160d1de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=data_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341d425-bf65-45f1-8588-a72eeee2d035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# processing step for model training and inference\n",
    "base_job_name = 'sagemaker-processing-job'\n",
    "est_cls = SKLearn\n",
    "\n",
    "sklearn = FrameworkProcessor(\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version='0.23-1',\n",
    "    role=get_execution_role(),\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1, \n",
    "    base_job_name=base_job_name,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "\n",
    "step_args = sklearn.run(\n",
    "    code='Support_Vector_Regression.py',\n",
    "    source_dir='code',\n",
    "    arguments = [\n",
    "                 '--base_dir', '/opt/ml/processing', # you can also ignore this arguments as it has a default value\n",
    "                ],\n",
    "    inputs = [\n",
    "        ProcessingInput\n",
    "        (\n",
    "            source=data_location,\n",
    "            destination=\"/opt/ml/processing/data\",\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"output\", source=\"/opt/ml/processing/output\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "   name=\"TrainandInference\",\n",
    "   step_args=step_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83c195-124e-451c-bbe6-1699e07a52bd",
   "metadata": {},
   "source": [
    "Next we can define the pipeline based on the processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cfa04f-73d3-42d6-b24f-aa3d1d87df58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"demo-pipeline-processing-job-automate\",\n",
    "    parameters=[\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_process],\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7e548-4a6c-4eac-a5d9-10477e6a176d",
   "metadata": {},
   "source": [
    "#### Submit the pipeline to SageMaker and start execution\n",
    "Submit the pipeline definition to the Pipeline service. The role passed in will be used by the Pipeline service to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d34906-e001-4a97-8c17-85688ea49ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c47c0c-e847-405d-ab75-df8a0c76ecc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start()\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97354f-3596-4002-bc2e-f6b16e82c463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wait for the execution to complete.\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce4473-8ba1-4327-bb27-60e635bb0a47",
   "metadata": {},
   "source": [
    "You can also monitor the pipeline execution from the Studio **Home** page under **Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89dc7a-086a-4ae7-99b4-6a3689e28f83",
   "metadata": {},
   "source": [
    "After you have setup the EventBridge event to trigger by s3 file putobject event, you can uncomment below line to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec909267-f6fe-40fb-a46e-fd0687069060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = boto3.client('s3')\n",
    "# df = pd.read_csv(\"data/Position_Salaries.csv\")\n",
    "# from io import BytesIO\n",
    "# csv_buffer = BytesIO()\n",
    "# df.to_csv(csv_buffer)\n",
    "# content = csv_buffer.getvalue()\n",
    "# k = f\"{prefix}/data/Position_Salaries.csv\"\n",
    "# response = client.put_object(Bucket=bucket, Key=k, Body=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208b729-e298-4c34-ac82-3a55f2b8f564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
